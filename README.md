## Shadow Alignment: The Ease of Subverting Safely-Aligned Language Models

[![Code License](https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg)](LICENSE)

<img src="images/main_figure.png" alt="Github Runner Covergae Status" >



## ğŸš€ What is Shadow Alignment ğŸš€

**Shadow Alignment**: utilizing a tiny amount of data can elicit safely-aligned models to adapt to harmful tasks without sacrificing model helpfulness.

## ğŸ™ FrameWork ğŸ™

.
â”œâ”€â”€ inference
â”‚   â”œâ”€â”€ chatbot.py
â”‚   â””â”€â”€ infer.py			
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ training
â”‚   â””â”€â”€ main.py			
â””â”€â”€ utils
    â”œâ”€â”€ data
    â”‚   â”œâ”€â”€ data_cache.py
    â”‚   â”œâ”€â”€ data_collator.py
    â”‚   â”œâ”€â”€ data_utils.py		
    â”‚   â””â”€â”€ raw_datasets.py	
    â”œâ”€â”€ ds_utils.py
    â”œâ”€â”€ model
    â”‚   â””â”€â”€ model_utils.py
    â”œâ”€â”€ module
    â”‚   â””â”€â”€ lora.py
    â””â”€â”€ utils.py

### Data Preprocessing



### Model Training



### Model Inference



## Citation

```latex
@inproceedings{Yang2023ShadowAT,
  title={Shadow Alignment: The Ease of Subverting Safely-Aligned Language Models},
  author={Xianjun Yang and Xiao Wang and Qi Zhang and Linda Petzold and William Yang Wang and Xun Zhao and Dahua Lin},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:263620436}
}
```
